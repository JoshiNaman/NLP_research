{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcKQeLww5kx8fZ4B4XouEU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","from torch.utils.data import DataLoader, Dataset\n"],"metadata":{"id":"Xw1VzVi4YvIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Define your own dataset class\n","class TweetDataset(Dataset):\n","    def __init__(self, tweets, labels):\n","        self.tweets = tweets\n","        self.labels = labels\n","        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","    def __len__(self):\n","        return len(self.tweets)\n","\n","    def __getitem__(self, idx):\n","        tweet = self.tweets[idx]\n","        label = self.labels[idx]\n","        encoding = self.tokenizer.encode_plus(\n","            tweet,\n","            add_special_tokens=True,\n","            max_length=128,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","        input_ids = encoding['input_ids'].squeeze()\n","        attention_mask = encoding['attention_mask'].squeeze()\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'label': torch.tensor(label)\n","        }\n"],"metadata":{"id":"DiyKox0pYzAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N79UqnCbYoUJ"},"outputs":[],"source":["\n","# Define your own training and evaluation data\n","train_tweets = [...]  # List of training tweets\n","train_labels = [...]  # List of corresponding training labels\n","eval_tweets = [...]  # List of evaluation tweets\n","eval_labels = [...]  # List of corresponding evaluation labels\n","\n","# Create instances of your dataset\n","train_dataset = TweetDataset(train_tweets, train_labels)\n","eval_dataset = TweetDataset(eval_tweets, eval_labels)\n","\n","# Define training parameters\n","batch_size = 32\n","epochs = 5\n","learning_rate = 2e-5\n","\n","# Load pretrained DistilBERT model and adjust it for sequence classification\n","model_name = 'distilbert-base-uncased'\n","model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Move model and datasets to the device\n","model.to(device)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","source":["\n","# Training loop\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    for batch in train_dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    avg_loss = total_loss / len(train_dataloader)\n","    print(f\"Epoch {epoch+1}/{epochs} - Avg. Training Loss: {avg_loss:.4f}\")\n"],"metadata":{"id":"BHan0lApY3Vw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","    # Evaluation loop\n","    model.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    for batch in eval_dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            eval_loss += outputs.loss.item()\n","            predicted_labels = torch.argmax(outputs.logits, dim=1)\n","            eval_accuracy += (predicted_labels == labels).sum().item()\n","\n","    avg_eval_loss = eval_loss\n"],"metadata":{"id":"qJVC35prY67T"},"execution_count":null,"outputs":[]}]}